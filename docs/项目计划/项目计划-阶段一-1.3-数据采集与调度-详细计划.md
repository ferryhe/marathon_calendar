# 项目计划 - 阶段一 - 1.3 数据采集系统（爬虫 + 调度）

## 目标与约束
- 目标：把赛事信息从“手工 seed”推进到“可配置、可追溯、可增量同步”的采集管线。
- 约束：采集/调度属于**管理员专用**能力，不应对普通用户开放。
- 原则：先做“框架 + 可运行 + 可观测 + 可扩展”，再逐步加站点适配器与 AI 兜底提取。

## 是否需要新增“管理员用户功能”？
结论：**第一版不强制需要新增用户角色**。
- 推荐的 MVP 方案：使用 `ADMIN_API_TOKEN` 保护 `/api/admin/*` 管理接口（常见于开源项目的内部管理/运维 API）。
- 后续（阶段二/三）再升级为：
  - 用户表增加 `role/isAdmin` 字段，配合 UI 管理后台登录
  - 或接入独立的管理后台（BasicAuth/OIDC）

## 参考项目（形态借鉴）
- RSSHub：插件化“数据源路由/适配器”结构，适合扩展多站点、多策略的数据源。
- changedetection.io：以“抓取原始内容 + content hash 变更检测 + 记录历史”为核心，可作为增量更新与可观测的参考。
- Airbyte：以“connector + 标准化输出 + sync run 记录”的数据同步理念为参考（本项目做轻量版）。

## 数据模型（落地到当前仓库）
本项目已有 `sources / marathon_sources / marathon_sync_runs`，在此基础上补齐：

### 1) sources（数据源目录）
用途：描述一个“连接器/来源”，含启用状态、重试、间隔等运行参数。
- `type`: official/platform/search
- `strategy`: HTML/RSS/API（后续可扩展）
- `isActive`, `retryMax`, `retryBackoffSeconds`, `requestTimeoutMs`, `minIntervalSeconds`
- `config`: JSONB（用于配置提取规则、Headers、解析参数等）

### 2) marathon_sources（赛事与数据源绑定）
用途：每个赛事在某个数据源上的具体 URL，以及增量同步状态。
- `sourceUrl`, `isPrimary`
- `lastCheckedAt`, `nextCheckAt`
- `lastHash`, `lastHttpStatus`, `lastError`

### 3) raw_crawl_data（原始抓取内容落库）
用途：保留原始内容，用于调试、回溯、AI兜底提取、差异分析。
- `rawContent`, `contentHash`, `httpStatus`, `contentType`, `metadata`, `status`

### 4) marathon_sync_runs（同步运行记录）
用途：可观测性与审计。
- `status`: running/success/retrying/failed
- `attempt`, `strategyUsed`, `message`
- `newCount/updatedCount/unchangedCount`
- `startedAt/finishedAt/errorMessage`

## 管线设计（简化版）
1. Scheduler tick（定时器）触发
2. 获取启用的 `sources`
3. 对每个 `marathon_sources` 判断是否 due（`nextCheckAt`/最小间隔）
4. Fetch（带超时、UA、重试）
5. 存 raw（内容变化时落库，写 content hash）
6. Extract（优先 JSON-LD Event；后续支持配置提取与 AI 兜底）
7. Merge/Upsert（写入 `marathon_editions`，更新 `lastSyncedAt`）
8. 记录 `marathon_sync_runs` + 更新 `marathon_sources` 的 last* 字段

### 混合提取策略（最佳实践：规则优先 → AI 兜底 → 人工复核）
参考：`docs/研究报告-数据提取与处理方案.md` 的 **2.4 混合方案（最佳实践）**。

1. **规则优先（成本低、速度快）**
   - 通用优先：JSON-LD Event（`startDate`）
   - 站点特化：`sources.config.extract`（CSS selector + attr + regex）
2. **AI 兜底（可选，默认关闭）**
   - 触发条件：规则无法提取到 `raceDate`
   - 环境变量：`AI_API_KEY`、`AI_MODEL`、`AI_BASE_URL`（可选）、`AI_ENABLE_FALLBACK=true`
   - 成本控制：仅失败时调用；HTML 截断；`temperature=0`
3. **人工复核队列（保证准确性）**
   - `raw_crawl_data.status`: `pending` → `processed` | `needs_review`
   - `needs_review` 的记录在管理界面集中查看，人工对照页面后完善 `sources.config.extract` 或手工修正数据

## 管理接口（管理员专用）
以 token 保护：
- `GET /api/admin/stats`：概览统计（sources/raw/runs 计数与近 24h 指标）
- `GET /api/admin/sources`：查看 sources
- `PUT /api/admin/sources/:id`：更新（启用/优先级/重试/间隔/策略/配置）
- `POST /api/admin/sync/run-all`：触发一次全量（按 due）
- `POST /api/admin/sync/run-marathon-source`：按 `marathonSourceId` 触发一次
- `GET /api/admin/sync/runs`：查看同步记录
- `GET /api/admin/raw-crawl`：查看最近 raw 记录（摘要）
- `GET /api/admin/discovery/web-search?q=...`：Brave 搜索，用于“赛事列表发现/详情页绑定”的半自动流程（需 `BRAVE_API_KEY`）

管理界面（Web，仅管理员自用）：
- `GET /admin/data`：Tab 化的管理入口（Overview/Sources/同步/绑定与发现/needs_review/定期更新；依赖 `ADMIN_API_TOKEN`）

## 调度与多实例
在生产环境可能存在多进程/多实例，必须避免重复抓取：
- 使用 Postgres advisory lock 做全局互斥（拿到锁的实例才执行）

## 里程碑拆解（按 commit 逐步验收）
### M1：数据模型与管理员入口（验收：能管理 sources，能触发同步）
- schema 补齐（sources/marathon_sources/marathon_sync_runs/raw_crawl_data）
- `/api/admin/*` token 保护与基础接口
- 文档：新增 env 说明（`.env.example`）

### M2：可运行的同步器（验收：能抓取、落 raw、写 sync run）
- scheduler 支持 due 判断、重试、hash 增量
- 保存 raw + run 记录
- 生产默认开启，开发需显式开启 `SYNC_SCHEDULER_ENABLED=true`

### M3：可扩展的提取与合并（验收：至少 1 种通用提取可把日期写回 editions）
- JSON-LD Event 提取 raceDate（通用）
- Upsert 到 `marathon_editions` 并更新 `lastSyncedAt`

### M3.5：混合方案落地（验收：失败可进入 needs_review；可按需启用 AI 兜底）
- `raw_crawl_data` 落库后写入 `processed/needs_review` 状态与提取元数据（method/fields）
- `AI_ENABLE_FALLBACK=true` 时，在规则提取不到 `raceDate` 的情况下调用 AI
- 管理界面 `/admin/data` 可查看运行记录、raw 队列并迭代配置规则
- raw 明细与复核回填：
  - `GET /api/admin/raw-crawl/:id`（查看 raw 内容/metadata）
  - `POST /api/admin/raw-crawl/:id/resolve`（回填到 editions 并标记 processed）
  - `POST /api/admin/raw-crawl/:id/ignore`（忽略）
- 字段级合并与冲突处理：
  - `marathon_editions.field_sources` 记录每个字段的来源与 rank
  - 合并优先级：official > platform > search（同类再按 priority）
  - 低优先级冲突不覆盖，raw 标记 needs_review，便于人工确认
 
### M3.6：管理后台信息架构优化（验收：清晰分区 + 一屏能看健康度）
- `/admin/data` 使用 Tab 分区（Overview/Sources/同步/绑定与发现/needs_review/定期更新）
- 增加 Overview 指标接口 `GET /api/admin/stats`（sources/raw/runs 计数 + 近 24h 指标）
- 目标：把“定期更新项目”的常见要素（任务分解、调度与单次触发分离、复核队列入口）在 UI 上显式化

### M4：数据源扩展与清洗（验收：5-10 个官网可跑通；平台源可配置）
- 扩展 sources 配置与站点特化（CSS selector 规则/regex 等）
- 数据标准化与去重策略（canonicalName + year）

### M5：发布态（Draft/Published）（验收：前台展示与后台抽取/复核解耦）
- `marathon_editions` 增加发布态（例如 `publishStatus` 或 `publishedAt`）
- 前台默认只展示 published；未确认数据（TBD/needs_review）进入独立区域或仅管理员可见
- 支持回滚与审计（发布动作有记录）

### M6：AI 规则模板生成器（验收：从 raw 一键生成可审计规则）
- 从某条 `raw_crawl_data` 调用 AI 生成 `sources.config.extract`（selector/attr/regex）模板
- 管理员审核后保存到 source config，并立即触发单次同步验证

## 风险与边界
- 真实网站反爬与动态渲染：HTML strategy 先覆盖“可直取”的站点；动态站点后续引入 Playwright/Puppeteer。
- 法律与 robots：建议仅抓取公开页面，并控制频率；必要时加白名单。
- 数据正确性：第一版偏“抓取留痕 + 可回溯”，提取准确度逐步提高。
